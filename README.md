# MarketML: Comparative Study on Machine Learning for Market Forecasting & Portfolio Optimization
## ðŸ“š Overview

This project is part of a research thesis titled **"A Comparative Study of Machine Learning Algorithms for Market Trend Forecasting and Portfolio Optimization"** (March 24, 2025). It integrates modern machine learning and optimization strategies to build robust models for:

- **Market Trend Forecasting**
- **Portfolio Optimization**

using historical data for **15 international top-tier firms** (2020â€“2024).

---

## ðŸ§  Key Methods

**Market Forecasting Algorithms:**
- ARIMA (`pmdarima`)
- LSTM (Keras/TensorFlow)
- Random Forest (Scikit-learn)
- XGBoost
- SVM (Scikit-learn)
- Transformer (Keras/TensorFlow)

**Portfolio Optimization Techniques:**
- Mean-Variance (Markowitz, `PyPortfolioOpt`)
- Black-Litterman (custom, using `PyPortfolioOpt`)
- Reinforcement Learning (PPO/A2C, `stable-baselines3`, `gymnasium`)

---

## ðŸ—‚ï¸ Project Structure

```
.ndmh/
â”œâ”€â”€ marketml/                   # Core library/package
â”‚   â”œâ”€â”€ analysis/               # Result analysis scripts
â”‚   â”œâ”€â”€ configs/                # Configurations
â”‚   â”œâ”€â”€ data_handling/          # Data loading/preprocessing
â”‚   â”œâ”€â”€ features/               # Feature engineering
â”‚   â”œâ”€â”€ models/                 # Forecasting models
â”‚   â”œâ”€â”€ portfolio_opt/          # Portfolio optimization & RL
â”‚   â”œâ”€â”€ pipelines/              # Pipeline scripts
â”‚   â””â”€â”€ utils/                  # Utilities
â”œâ”€â”€ data_input/                 # Raw data (CSVs)
â”œâ”€â”€ data_processed/             # Processed/enriched data
â”œâ”€â”€ forecasts_output/           # Forecast results
â”œâ”€â”€ logs/                       # Logs
â”œâ”€â”€ results_output/             # Experiment results, models
â”œâ”€â”€ notebooks/                  # Jupyter notebooks
â”œâ”€â”€ tests/                      # Tests
â”œâ”€â”€ run_pipeline.py             # Pipeline entry point
â”œâ”€â”€ setup.py                    # Packaging script
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

---

## ðŸ’¾ Data

- **Input Data:**  
  - `yahoo_price_data_fixed.csv` (2020â€“2024 prices, Yahoo Finance)  
  - `financial_data.csv` (Financial statements, Annual Report, Macrotrends)  
  Place in `.ndmh/data_input/`

- **Processed Data:**  
  - `price_data_enriched_v2.csv` (prices + ~20 technical indicators, GARCH)  
  - `classification_probabilities.csv` (trend probabilities for Black-Litterman/RL)  
  Generated by pipeline scripts, saved in `.ndmh/data_processed/` and `.ndmh/results_output/`

- **Output Data:**  
  - Forecasts: `.ndmh/forecasts_output/`
  - Model/portfolio performance: `.ndmh/results_output/`
  - RL models: `.ndmh/results_output/rl_models/`
  - Plots: `.ndmh/results_output/plots/`

---

## âš™ï¸ Technology Stack

- Python 3.8+
- Pandas, NumPy, SciPy
- Scikit-learn, XGBoost, Pmdarima
- TensorFlow/Keras
- Gymnasium, Stable-Baselines3
- PyPortfolioOpt
- Matplotlib, Seaborn, QuantStats

---

## ðŸš€ Getting Started

1. **Prerequisites:**  
   - Python 3.8+  
   - `pip` and `venv` (or `conda`)

2. **Setup Environment:**
   ```bash
   python -m venv .venv
   source .venv/bin/activate      # Linux/macOS
   # .venv\Scripts\activate.bat   # Windows (cmd)
   pip install -r requirements.txt
   pip install -e .
   ```

3. **Prepare Input Data:**  
   Place `yahoo_price_data_fixed.csv` and `financial_data.csv` in `.ndmh/data_input/`

4. **Run the Pipeline:**  
   Main entry: `run_pipeline.py` (in `.ndmh/`)
   ```bash
   python run_pipeline.py all
   python run_pipeline.py build_features
   python run_pipeline.py build_features train_forecasting
   python run_pipeline.py run_backtests
   ```
   Or run individual scripts:
   ```bash
   python -m marketml.pipelines.01_build_features
   python -m marketml.pipelines.02_train_forecasting_models
   ```

---

## ðŸ“Š Expected Outputs

- Logs: `.ndmh/logs/`
- Processed data: `.ndmh/data_processed/`
- Forecast/model metrics: `.ndmh/results_output/`
- Forecasts: `.ndmh/forecasts_output/`
- Signal probabilities: `.ndmh/results_output/`
- Portfolio backtests: `.ndmh/results_output/`
- RL models: `.ndmh/results_output/rl_models/`
- Plots: `.ndmh/results_output/plots/`

---

## ðŸ” Research Objective

To empirically compare forecasting and portfolio optimization algorithms across international companies, evaluating:

- **Forecasting accuracy:** (Accuracy, F1-score, Precision, Recall)
- **Portfolio performance:** (Sharpe Ratio, Sortino Ratio, Cumulative Return, Max Drawdown)

---

> _Note: If using a VM or shared data mount, update data paths in `configs.py` as needed._
